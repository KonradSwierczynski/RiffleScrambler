\chapter{Preliminaries}
\thispagestyle{chapterBeginStyle}
\label{rozdzial1}

W dalszej części używana będzie następująca notacja.
Zbiory $\mathbb{N} = \{ 0,1,2,\dots \}$, $ \mathbb{N}^{+} = \{ 1, 2, \dots \}$.
$[c] := \{1, 2,\dots,c \}$ oraz $[b, c] = \{ b, b+1, \dots, c \}$, gdzie $b, c \in \mathbb{N}$ oraz $b \leq c$.

Skierowany graf acykliczny (ang. \textit{directed acyclic graph}, DAG) $G = (V, E)$ jest rozmiaru $n$ jeżeli $|V| = n$.
Wierzchołek $v \in V$ ma stopień wchodzący $\delta$ równy największemu stopniu wchodzącemu wśród jego wierzchołków $\delta = indeg(v)$, jeżeli istnieje $\delta$ wchodzących krawędzi $\delta = | \left( V \times {v} \right) \cap E|$.
Graf $G$ ma stopień wchodzący $ \delta = indeg(G) = \max_{v \in V} indeg(v)$.
Wierzchołki o stopniu wchodzącym 0 nazywane są źródłami, a wierzchołki bez krawędzi wychodzących nazywane są ujściami.

Zbiór rodziców wierzchołka $v \in V$ oznaczany jest jako $parents_{G}(v) = \{ u \in V: (u, v) \in E \}$.
Uogólniając, zbiór przodków $v$ oznaczany jest jako $ancestors_{G}(v) = \bigcup_{i \geq 1}parents_{G}^{i}(v)$, przyjmując $parents_{G}^{i+1}(v) = parents_{G}(parents_{G}^{i}(v)))$. Jeżeli wybór grafu $G$ wynika z kontekstu, będziemy oznaczać te zbiory jako $parents$ oraz $ancestors$.

Zbiór wszystkich ujść w grafie $G$ oznaczany jest jako $sinks(G) = \{ v \in V : \nexists (v, u) \in E \}$. DAG G, który jest spójny, a tylko takie będą rozważane w dalszej części pracy, zachowuje równość $ancestors(sinks(G)) = V$.

Dla skierowanej ścieżki $p = (v_{1},v_{2},\dots,v_{z})$ w $G$, jej długość jest równa ilości wierzchołku przez które przechodzi $length(p) := z$.
Mając DAG G, oznaczamy długość jego najdłuższej ścieżki jako $depth(G)$.

Mając podzbiór wierzchołków grafu $S \subset V$, poprzez $G - S$ oznaczać będziemy DAG otrzymany z $G$ poprzez usunięcie wierzchołków z $S$ oraz krawędzi wychodzących lub wchodzących do wierzchołków z $S$.

\section{Etykietowanie Grafu}

\begin{definition}
	(\textit{Parallel/Sequential Graph Pebbling}). Niech $G = (V, E)$ będzie grafem skierowanym grafem acyklicznym i niech $T \subset V$ będzie zbiorem wierzchołków do oetykietowania. $T$ będzie nazywane celem.
	Stanem etykietowania $G$ jest zbiór $P_{i} \subset V$.
	Poprawnym etykietowaniem równoległym jest ciąg $P = (P_{0}, \dots , P_{t})$ stanów etykietowania $G$,
	gdzie $P_{0} = \emptyset $ oraz gdzie spełnione są warunki 1 oraz 2 poniżej.
	Etykietowanie sekwencyjne musi dodatkowo spełniać warunek 3.
	\begin{enumerate}
		\item Każdy wierzchołek z celu jest w pewnej konfiguracji oetykietowany (nie koniecznie wszystkie jednocześnie).
		$$ \forall x \in T \exists x \leq t : x \in P_{x} $$
		
		\item Oetykietować wierzchołek można tylko wtedy, gdy wszyscy jego rodzice
		są oetykietowani w poprzednim kroku.
		$$ \forall i \in [t] : x \in (P_{i} \setminus P_{i-1}) \Rightarrow parents(x) \subset P_{i-1} $$
		
		\item W każdym kroku można oetykietować co najwyżej jeden wierzchołek.
		$$ \forall i \in [t]: | P_{i} \setminus P_{i-1} | \leq 1 $$
	\end{enumerate}
	Zbiory poprawnych etykietowań sekwencyjnych i równoległych grafu G z celem T oznaczamy odpowiednio jako 
	$ \mathcal{P}_{G,T} $ oraz $ \mathcal{P}_{G,T}^{ \parallel } $.
	Etykietowania najbardziej interesujących przypadków, gdy $T = sinks(G)$, oznaczamy $ \mathcal{P}_{G} $ oraz $ \mathcal{P}_{G}^{ \parallel } $.
\end{definition}


 Można zauważyć, że $ \mathcal{P}_{G,T} \subset  \mathcal{P}_{G,T}^{ \parallel } $.

\begin{definition}
	Złożoność czasową (ang. \textit{time}, t), pamięciową (ang. \textit{space}, s), pamięciowo-czasową (ang. \textit{space-time}, st) oraz łączna (ang. \textit{cumulative}, cc) etykietowania $ P = (P_{0}, \dots , P_{t} ) \in \mathcal{P}_{G}^{ \parallel } $ są zdefiniowane jako
	$$ \Pi_{t}(P) = t, \Pi_{s}(P) = \max_{y \in [t]} | P_{i} |, \Pi_{st}(P) = \Pi_{t}(P) * \Pi_{s}(P), \Pi_{cc}(P) = \sum_{i \in [t]}| P_{i}|$$
	Dla $ \alpha \in \{s, t, st, cc \}$ oraz celu $T \subset V $, złożoności sekwencyjnego oraz równoległego
	etykietowania grafu $G$ definiujemy jako
	$$ \Pi_{ \alpha }(G, T) = \min_{P \in \mathcal{P}_{G,T}} \Pi_{ \alpha } (P) $$
	$$ \Pi_{ \alpha }^{ \parallel }(G, T) = \min_{P \in \mathcal{P}_{G,T}^{ \parallel }} \Pi_{ \alpha } (P) $$
	Kiedy $T = sinks(G)$, piszemy $ \Pi_{ \alpha }^{ \parallel }(G) $ oraz $ \Pi_{ \alpha }(G) $.
	
\end{definition}

Ponieważ $ \mathcal{P}_{G,T} \subset  \mathcal{P}_{G,T}^{ \parallel } $, dla dowolnej złożoności etykietowania $ \alpha \in \{s, t, st, cc \}$ oraz dowolnego grafu $G$ złożoność etykietowania równoległe jest nie większa, niż złożoność etykietowania sekwencyjnego $ \Pi_{ \alpha }(G) \geq \Pi_{ \alpha}^{\parallel}(G)$, a złożoność łączna jest nie większa, niż czasowo-pamięciowa  $ \Pi_{ st }(G) \geq \Pi_{ cc }(G)$ i $ \Pi_{ st }^{ \parallel }(G) \geq \Pi_{ cc }^{ \parallel }(G)$.

W tej pracy głównie rozważane jest badanie złożoności $\Pi_{ st }$, oraz $\Pi_{ cc }^{ \parallel }$, ponieważ ukazują one kolejno koszt przeprowadzania etykietowania na jednordzeniowej maszynie (np. procesor x86) oraz koszt etykietowania na wyspecjalizowanym układzie.

Aby zobaczyć jakie wartości mogą przyjąć przedstawione złożoności, rozważmy graf rozmiaru $n$.
Każdy graf rozmiaru $n$ może zostać oetykietowany w $n$ krokach, ponieważ ma tylko $n$ wierzchołków. Każdy stan etykietowania nie może również zawierać więcej niż $n$ elementów. Zatem górne ograniczenie możemy przedstawić następująco
$$ \forall G_{n} \in \mathbb{G}_{n} : \Pi_{ cc }^{ \parallel }(G_{n}) \leq \Pi_{ st }(G_{n}) \leq n^{2} . $$

Zobaczmy jak wyglądają złożoności dla grafu pełnego $K_{n} = (V = [n], E= \{
(i,j): 1 \leq i < j \leq n \})$ oraz dla $Q_{n} = (V = [n], E = \{ (i, i+1) : 1 \leq n \} )$.
$$ n(n - 1) / 2 \leq \Pi_{ cc }^{ \parallel }(K_{n}) \leq \Pi_{ st }(K_{n}) \leq n^2$$
Graf $K_{n}$ maksymalizuje złożoności etykietowania, a  $\Pi_{ cc }^{ \parallel }$ jest rożne tylko o stałą od $\Pi_{ st }$. Co oznacza, że koszt obliczania funkcji opartej na takim grafie byłby zdominowany przez koszt dostępu do pamięci, a wyspecjalizowane układy nie dały by dużej przewagi nad tradycyjnym procesorem. Jest to bardzo pożądane dla funkcji memory-hard, jednak ze względu na bardzo wysoki stopień grafu $K_{n}$, nie jest on przydatny przy konstruowaniu MHF.
Stopień wchodzący w grafie $Q_{n}$ jest równy 1, jednak złożoność etykietowania jest bardzo niska
$$ \Pi_{ cc }^{ \parallel }(Q_{n}) = \Pi_{ st }(Q_{n}) \leq n. $$ 
Oznacza to, że koszt obliczania funkcji opartej na takim grafie (taką funkcją jest PBKDF2) nie jest zależny w dużej mierze od kosztu dostępu do pamięci nawet dla dużego $n$. 



\section{Superkoncentrator}
Superkoncentrator jest grafem, w którym moc zbioru przodków dla wierzchołków szybko rośnie wraz z numerem pokolenia. Oznacza to, że zbiór kolejnych wierzchołków, będzie posiadał liczebny zbiór rodziców, co czyni superkoncentrator bardzo przydatnym do konstrukcji MHF.
\begin{definition}
	(N-Superkoncentrator). Skierowany graf acykliczny $G = (V, E)$ o ustalonym stopniu wchodzącym, $N$ wejściach i
	$N$ wyjściach nazywany jest N-Superkoncentratorem, gdy dla każdego $k \in [N]$
	oraz dla każdej pary podzbiorów $V_{1} \subset V$ $k$ wejść i $V_{2} \subset V$ $k$ wyjść istnieje
	$k$ wierzchołkowo-rozłącznych ścieżek łączących wierzchołki ze zbioru $V_{1}$ z wierzchołkami w $V_{2}$.
\end{definition}

\begin{definition}
	((N, $\lambda$)-Superkoncentrator). Niech $G_{i}, i = 0, \dots, \lambda-1$ będą N-Superkoncentratorami.
	Niech graf $G$ będzie połączeniem wyjść $G_{i}$ do odpowiadających wejść w $G_{i+1}$ dla $i = 0, \dots, \lambda - 2$.
	Graf $G$ jest nazywany (N, $\lambda$)-Superkoncentratorem.
\end{definition}

\begin{theorem}
	(Ograniczenie dolne dla (N, $ \lambda $)-Superkoncentratora).
	Etykietowanie (N, $\lambda$)-Superkoncentratora używając $S \leq N/20$ etykiet, wymaga $T$ kroków, gdzie
	$$ T \geq N \left( \frac{ \lambda N}{64 S} \right) ^{ \lambda }.$$
\end{theorem}

\section{Grafy Depth-Robust}

Alwen i Blocki w swojej pracy [] //TODO
pokazali, że istnieje zależność między złożonością etykietowania, a depth-robustness. Na podstawie tej właściwości potrafimy określić dolne i górne ograniczenie $\Pi_{ cc }^{ \parallel }$.

\begin{definition}
	(Depth-Robustness). Dla $n \in \mathbb{N}$ oraz $e, d \in [n]$ DAG $G = (V, E)$
	jest (e, d)-depth-robust, jeżeli
	$$ \forall S \subset V \ | S | \leq e \Rightarrow depth(G - S) \geq d.$$
\end{definition}

\begin{theorem}
	Niech DAG G będzie (e, d)-depth-robust, wtedy $ \Pi_{ cc }^{ \parallel } > ed$.
\end{theorem}

\begin{definition}
	Jeżeli graf $G$ nie jest (e,d)-depth-roubust to nazywany jest (e,d)-reducible.
\end{definition}

\begin{theorem}
	Niech $G \in \mathbb{G}_{n, \delta}$ taki, że $G$ jest (e,d)-reducible. Wtedy
	$$ \Pi_{cc}^{\parallel}(G) = O \left( \min_{g \in [d,n]} \Big \lbrace n \left( \frac{dn}{g} + \delta g + e \right) \Big \rbrace \right) $$
	biorąc $g = \sqrt{ \frac{dn}{g}}$ upraszcza się to do $ \Pi_{cc}^{\parallel}(G) = O \left( n ( \sqrt{dn \delta} + e) \right)$.
\end{theorem}

\section{Dispresed Graphs}

\begin{definition}
	(Dependencies). Niech $G = (V, E)$ będzie acyklicznym grafem skierowanym.
	Niech $L \subseteq V$.
	Mówimy, że $L$ ma ($z$, $g$)-dependency jeżeli istnieją wierzchołkowo rozłączne ścieżki $p_{1}, \dots , p_{z}$ kończące się w $L$, gdzie każda jest długości co najmniej $g$.
\end{definition}

\begin{definition}
	(Dispresed Graph). Niech $g, k \in \mathbb{N}$ i $g \geq k$. DAG G jest nazywany (g, k)-dispresed jeżeli istnieje uporządkowanie jego wierzchołków takie, że następujące warunki są spełnione.
	Niech $[k]$ oznacza ostatnie $k$ wierzchołków o uporządkowaniu G i niech $L_{j} = [jg, (j + 1)g - 1]$ będzie j-tym podprzedziałem.
	Wtedy $\forall j \in [ \lfloor k / g \rfloor ]$ przedział $L_{j}$ ma (g, g)-dependency.
	W ogólności, jeżeli dla $ \epsilon \in (0, 1] $ każdy przedział $L_{j}$ ma tylko ($\epsilon$g, g)-dependency, graf G nazywany jest ($\epsilon$, g, g)-dispresed.
\end{definition}

\begin{definition}
	Acykliczny graf skierowany $G = (V, E)$ nazywany jest ($\lambda$,$\epsilon$,g,k)-dispresed jeżeli istnieje $\lambda \in \mathbb{N}^{+} $ rozłącznych podzbiorów wierzchołków \{$ L_{i} \subseteq V$\},
	każdy o rozmiarze $k$ oraz spełnione są następujące warunki.
	\begin{enumerate}
		\item Dla każdego $L_{i}$ istnieje ścieżka przechodząca przez wszystkie wierzchołki $L_{i}$.
		
		\item Dla ustalonego porządku topologicznego G. Dla każdego $i \in [\lambda]$ niech
		$G_{i}$ będzie podgrafem G, zawierającym wszystkie wierzchołki z G, aż do ostatniego wierzchołka z $L_{i}$. $G_{i}$ jest ($\epsilon$,g,k)-dispresed.
	\end{enumerate}
	Zbiór grafów, które są ($\lambda$, $\epsilon$, g, k)-dispresed oznaczamy jako $\mathbb{D}_{\epsilon,g}^{\lambda,k}$.
\end{definition}

\begin{theorem}
	Niech $G \in \mathbb{D}_{\epsilon,g}^{\lambda,k}$.
	$$ \Pi_{cc}^{\parallel}(G) \geq \epsilon \lambda g \left( \frac{k}{2} - g \right) $$
\end{theorem}


\section{Grafy Warstwowe}

\begin{definition}
	($\lambda$-Stacked Sandwich Graphs). Niech $n, \lambda \in \mathbb{N}^{+}$ takie, że $\lambda + 1$ dzieli $n$ oraz niech $k=n/(\lambda + 1)$. Mówimy, że graf $G$ jest $\lambda$-stacked sandwich DAG, jeżeli $G$ zawiera ścieżkę przechodzącą przez $n$ wierzchołków $(v_{1},\dots,v_{n})$ oraz dzieląc go na warstwy $L_{j} = \{v_{jk + 1},\dots,v_{jk + k} \}$, dla $j \in \{0,\dots,\lambda\}$, pozostałe krawędzie łączą wierzchołki z niższej warstwy $L_{j}$ jedynie z wierzchołkami z wyższych warstw $L_{i}$, $i \in \{ j+1,\dots,\lambda \}$.
\end{definition}



\begin{lemma}
	Niech $G$ będzie $\lambda$-stacked sandwich DAG, wtedy dla dowolnego $t \in \mathbb{N}^{+}$, $G$ jest $(n/t, \lambda t)$-reducible.
\end{lemma}


\section{Ograniczenia Złożoności RSG}

\begin{theorem}
	Niech $ \lambda, n \in \mathbb{N}^{+}$ takie, że $n = \overline{n}(2 \lambda c + 1) $, gdzie $c \in \mathbb{N}$ i $ \overline{n} = 2^{c}$.
	Wtedy dla $ g = \lfloor \sqrt{ \overline{n}} \rfloor$
	$ RSG_{\lambda}^{ \overline{n}} \in \mathbb{D}_{1,g}^{\lambda, \overline{n}} $
	oraz
	$ \Pi_{cc}^{ \parallel }(RSG_{\lambda}^{\overline{n}}) = \Omega \left( \frac{n^{1.5}}{c \sqrt{c \lambda}} \right) $.
\end{theorem}

\begin{proof}
	Niech $G = RSG_{\lambda}^{ \overline{n}}$, niech $G_{1}, G_{2}, \dots , G_{ \lambda }$ będą
	podgrafami $G$ opisanymi w DEF[...].
	Pokażemy, że każdy $G_{i}$ jest (g, $\overline{n}$)-dispresed dla $g = \lfloor \sqrt{ \overline{n}} \rfloor $.
	
	Wybierzmy $i \in [ \lambda ]$ niech $L_{1}$ będzie ostatnimi $\overline{n}$ wierzchołkami w porządku topologicznym grafu $G_{i}$.
	Oznaczamy wierzchołki zbioru $L_{1}$ poprzez ${1} \times [ \overline{n} ]$, gdzie druga pozycja odpowiada kolejności wierzchołka w porządku topologicznym.
	Niech $ \overline{g} = \lfloor \overline{n} / g \rfloor$, dla każdego $j \in [ \overline{g}]$
	$L_{1, j} = \{ <1, jg + x> : x \in [0, g-1] \}$.
	Pokażemy, że wszystkie $L_{1, j}$ mają (g, g)-dependency.
	
	Niech $L_{0}$ będzie $\overline{n}$ pierwszymi wierzchołkami $G_{i}$, które oznaczamy ${0} \times [\overline{n}]$ (ponownie druga pozycja odpowiada porządkowi topograficznemu).
	Zauważmy, że dla $n \textgreater 1$ i $g = \lfloor \sqrt{ \overline{n}} \rfloor$ prawdą jest, że $g(g - 2c + 1) \leq n$.
	Zatem zbiór $S = \{ <0, i(g - 2c + 1_)>: i \in [g] \}$ jest całkowicie zawarty w $L_{0}$.
	
	Z własności $RSG$ [Superconcentrator- ....] wynika, że skoro zbiory $S$ oraz $L_{1,j}$ mają po $g$ wierzchołków, to istnieje $g$ wierzchołkowo-rozłącznych ścieżek o długości $2c$ między wierzchołkami tych zbiorów. Zatem $L_{1,j}$ ma (g, 2c)-dependency.
	
	Rozszerzmy to do (g,g)-dependency.
	Niech ścieżka $p$ zaczynająca się w wierzchołku $<0, v> \in S$ będzie ścieżką w (g, 2c)-dependency $L_{1,j}$. Zauważmy, że istnieje ścieżka przechodząca przez wszystkie wierzchołki $L_{0}$ oraz, że wierzchołki zbiory $S$ są oddzielone między sobą o $g - 2c$ wierzchołków.
	Możemy dodać na początek ścieżki $p$ ścieżkę $( <0, v - (g - 2c - 1)>, <0, v - (g - 2c -2)>, \dots, <0, v>)$.
	Otrzymujemy w ten sposób ścieżkę $p_{+}$ o długości $2c + g - 2c = g$.
	Ponieważ każda para ścieżek $p \neq q$ w (g, 2c)-dependency $L_{1,j}$ jest wierzchołkowo-rozłączna,
	to w szczególności zaczynać się muszą w różnych wierzchołkach $<0, v_{p}> \neq <0, v_{q}>$.
	Ponieważ wierzchołki w $S$ są od siebie oddalone o $g - 2c$ wierzchołków, zatem ścieżki $p^{+}$ i $q_{+}$ nadal pozostają rozłączne.
	Rozszerzając w ten sposób wszystkie ścieżki z (g, 2c)-dependency otrzymujemy ścieżki wierzchołkowo-rozłączne długości $g$. Z tego wynika, że $L_{1,j}$ ma (g, g)-dependency, co dowodzi, że $ RSG_{\lambda}^{ \overline{n}} \in \mathbb{D}_{1,g}^{\lambda, \overline{n}} $.
	Pozostaje obliczyć górne ograniczenie używając [Theorem 6 ABP2017].
	
	$$ \Pi_{cc}^{ \parallel }(RSG_{\lambda}^{\overline{n}}) = \lambda g \left( \frac{ \overline{n}}{2} - g \right) \geq \lambda \lfloor \sqrt{ \overline{n}} \rfloor \left( \frac{ \overline{n}}{2} - \lfloor \sqrt{ \overline{n}} \rfloor \right) = \lambda \sqrt{ \overline{n}} \left( \frac{ \overline{n}}{2} - \sqrt{ \overline{n}} \right) - O(\overline{n}) =  \Omega \left( \lambda \overline{n} \right) = \Omega \left( \frac{n^{1.5}}{c \sqrt{c \lambda}} \right) $$
	
\end{proof}



\begin{theorem}
	Niech $\lambda, g \in \mathbb{N}^{+}$, $N = 2^{g}$, $n = N(2 \lambda g + 1)$, wtedy
	$$ \Pi_{cc}^{ \parallel }(RSG_{\lambda}^{\overline{n}}) = O \left( n^{1.\overline{6}} \right) $$
\end{theorem}

\begin{proof}
	Kożystając, z [...], $RSG_{\lambda}^{N}$ jest $\lambda$-Stacked Sandwich Graph.
	Z [Lemma 4.2 AB16] wynika więc, że $RSG_{\lambda}^{N}$  jest ($n / t$, $\lambda + t - \lambda - 1$)-reducible dla dowolnego $t \geq 1$.
	Z twierdzenia 10 [ABP17] wynika, że $\Pi_{cc}^{ \parallel }(RSG_{\lambda}^{\overline{n}}) = O \left( n \left( \sqrt{( \lambda t + t - \lambda - 1)n \delta } + \frac{n}{t} \right) \right)$.
	Aby dostać najdokładniejsze (najmniejsze) ograniczenie górne trzeba zminimalizować
	$n \left( \sqrt{( \lambda t + t - \lambda - 1)n \delta } + \frac{n}{t} \right)$.
	Zanim jednak przejdziemy do minimalizowania, uprośćmy nieco to wyrażenie
	$$ n \left( \sqrt{( \lambda t + t - \lambda - 1)n \delta } + \frac{n}{t} \right) \leq n \left( \sqrt{ 2\lambda t n \delta } + \frac{n}{t} \right) .$$
	Teraz możemy znaleźć minimum względem naszego parametru $t$.
	$$ \frac{\partial}{\partial t} n \left( \sqrt{( 2\lambda t)n \delta } + \frac{n}{t} \right) = \frac{ \sqrt{ 2 \delta \lambda n^{3} }}{2t} - \frac{n^{2}}{t^{2}}$$
	Minimum znajduje się w punkcje, gdzie pochodna ma wartość zero.
	$$ \frac{ \sqrt{ 2 \delta \lambda n^{3} }}{2t} - \frac{n^{2}}{t^{2}} = 0$$
	$$ t = \frac{2n^{2}}{ \sqrt{ 2 \delta \lambda n^{3} }} = O \left( n^{\frac{1}{3}} \right) $$
	Zatem podstawiając $t$ minimalizujące ograniczenie górne do wzoru z twierdzenie 10 [ABP17] otrzymujemy
	$$ \Pi_{cc}^{ \parallel }(RSG_{\lambda}^{\overline{n}}) = O \left( n \left( \sqrt{( \lambda n^{\frac{1}{3}} + n^{\frac{1}{3}} - \lambda - 1)n \delta } + \frac{n}{n^{\frac{1}{3}}} \right) \right) = O \left( n^{1.\overline{6}} \right) $$
\end{proof}





