\chapter{Preliminaries}
\thispagestyle{chapterBeginStyle}
\label{rozdzial1}

W dalszej części używana będzie następująca notacja.
Zbiory $\mathbb{N} = \{ 0,1,2,\dots \}$, $ \mathbb{N}^{+} = \{ 1, 2, \dots \}$.
$[c] := \{1, 2,\dots,c \}$ oraz $[b, c] = \{ b, b+1, \dots, c \}$, gdzie $b, c \in \mathbb{N}$ oraz $b \leq c$.

Skierowany graf acykliczny (ang. \textit{directed acyclic graph}, DAG) $G = (V, E)$ jest rozmiaru $n$ jeżeli $|V| = n$.
Wierzchołek $v \in V$ ma stopień wchodzący $\delta$ równy największemu stopniu wchodzącemu wśród jego wierzchołków $\delta = \mathbf{indeg}(v)$, jeżeli istnieje $\delta$ wchodzących krawędzi $\delta = | \left( V \times {v} \right) \cap E|$.
Graf $G$ ma stopień wchodzący $ \delta = \mathbf{indeg}(G) = \max_{v \in V} \mathbf{indeg}(v)$.
Wierzchołki o stopniu wchodzącym 0 nazywane są źródłami, a wierzchołki bez krawędzi wychodzących nazywane są ujściami.

Zbiór rodziców wierzchołka $v \in V$ oznaczany jest jako $\mathbf{parents}_{G}(v) = \{ u \in V: (u, v) \in E \}$.
Uogólniając, zbiór przodków $v$ oznaczany jest jako $\mathbf{ancestors}_{G}(v) = \bigcup_{i \geq 1}\mathbf{parents}_{G}^{i}(v)$, przyjmując $\mathbf{parents}_{G}^{i+1}(v) = \mathbf{parents}_{G}(\mathbf{parents}_{G}^{i}(v)))$. Jeżeli wybór grafu $G$ wynika z kontekstu, będziemy oznaczać te zbiory jako $\mathbf{parents}$ oraz $\mathbf{ancestors}$.

Zbiór wszystkich ujść w grafie $G$ oznaczany jest jako $\mathbf{sinks}(G) = \{ v \in V : \nexists (v, u) \in E \}$. DAG G, który jest spójny, a tylko takie będą rozważane w dalszej części pracy, zachowuje równość $\mathbf{ancestors}(\mathbf{sinks}(G)) = V$.

Dla skierowanej ścieżki $p = (v_{1},v_{2},\dots,v_{z})$ w $G$, jej długość jest równa ilości wierzchołku przez które przechodzi $\mathbf{length}(p) := z$.
Mając DAG G, oznaczamy długość jego najdłuższej ścieżki jako $\mathbf{depth}(G)$.

Mając podzbiór wierzchołków grafu $S \subset V$, poprzez $G - S$ oznaczać będziemy DAG otrzymany z $G$ poprzez usunięcie wierzchołków z $S$ oraz krawędzi wychodzących lub wchodzących do wierzchołków z $S$.

\section{Etykietowanie grafu}

\begin{definition} [\textit{Równoległe/sekwencyjne etykietowanie grafu}] Niech $G = (V, E)$ będzie grafem skierowanym grafem acyklicznym i niech $T \subset V$ będzie zbiorem wierzchołków do oetykietowania. $T$ będzie nazywane celem.
	Stanem etykietowania $G$ jest zbiór $P_{i} \subset V$.
	Poprawnym etykietowaniem równoległym jest ciąg $P = (P_{0}, \dots , P_{t})$ stanów etykietowania $G$,
	gdzie $P_{0} = \emptyset $ oraz gdzie spełnione są warunki 1 oraz 2 poniżej.
	Etykietowanie sekwencyjne musi dodatkowo spełniać warunek 3.
	\begin{enumerate}
		\item Każdy wierzchołek z celu jest w pewnej konfiguracji oetykietowany (nie koniecznie wszystkie jednocześnie).
		$$ \forall x \in T \exists x \leq t : x \in P_{x} $$
		
		\item Oetykietować wierzchołek można tylko wtedy, gdy wszyscy jego rodzice
		są oetykietowani w poprzednim kroku.
		$$ \forall i \in [t] : x \in (P_{i} \setminus P_{i-1}) \Rightarrow \mathbf{parents}(x) \subset P_{i-1} $$
		
		\item W każdym kroku można oetykietować co najwyżej jeden wierzchołek.
		$$ \forall i \in [t]: | P_{i} \setminus P_{i-1} | \leq 1 $$
	\end{enumerate}
	Zbiory poprawnych etykietowań sekwencyjnych i równoległych grafu G z celem T oznaczamy odpowiednio jako 
	$ \mathcal{P}_{G,T} $ oraz $ \mathcal{P}_{G,T}^{ \parallel } $.
	Etykietowania najbardziej interesujących przypadków, gdy $T = \mathbf{sinks}(G)$, oznaczamy $ \mathcal{P}_{G} $ oraz $ \mathcal{P}_{G}^{ \parallel } $.
\end{definition}


 Można zauważyć, że $ \mathcal{P}_{G,T} \subset  \mathcal{P}_{G,T}^{ \parallel } $.

\begin{definition}
	Złożoność czasową (ang. \textit{time}, t), pamięciową (ang. \textit{space}, s), pamięciowo-czasową (ang. \textit{space-time}, st) oraz łączna (ang. \textit{cumulative}, cc) etykietowania $ P = (P_{0}, \dots , P_{t} ) \in \mathcal{P}_{G}^{ \parallel } $ są zdefiniowane jako
	$$ \Pi_{t}(P) = t, \Pi_{s}(P) = \max_{y \in [t]} | P_{i} |, \Pi_{st}(P) = \Pi_{t}(P) * \Pi_{s}(P), \Pi_{cc}(P) = \sum_{i \in [t]}| P_{i}|$$
	Dla $ \alpha \in \{s, t, st, cc \}$ oraz celu $T \subset V $, złożoności sekwencyjnego oraz równoległego
	etykietowania grafu $G$ definiujemy jako
	$$ \Pi_{ \alpha }(G, T) = \min_{P \in \mathcal{P}_{G,T}} \Pi_{ \alpha } (P) $$
	$$ \Pi_{ \alpha }^{ \parallel }(G, T) = \min_{P \in \mathcal{P}_{G,T}^{ \parallel }} \Pi_{ \alpha } (P) $$
	Kiedy $T = \mathbf{sinks}(G)$, piszemy $ \Pi_{ \alpha }^{ \parallel }(G) $ oraz $ \Pi_{ \alpha }(G) $.
	
\end{definition}

Ponieważ $ \mathcal{P}_{G,T} \subset  \mathcal{P}_{G,T}^{ \parallel } $, dla dowolnej złożoności etykietowania $ \alpha \in \{s, t, st, cc \}$ oraz dowolnego grafu $G$ złożoność etykietowania równoległe jest nie większa, niż złożoność etykietowania sekwencyjnego $ \Pi_{ \alpha }(G) \geq \Pi_{ \alpha}^{\parallel}(G)$, a złożoność łączna jest nie większa, niż czasowo-pamięciowa  $ \Pi_{ st }(G) \geq \Pi_{ cc }(G)$ i $ \Pi_{ st }^{ \parallel }(G) \geq \Pi_{ cc }^{ \parallel }(G)$.

W tej pracy głównie rozważane jest badanie złożoności $\Pi_{ st }$, oraz $\Pi_{ cc }^{ \parallel }$, ponieważ ukazują one kolejno koszt przeprowadzania etykietowania na jednordzeniowej maszynie (np. procesor x86) oraz koszt etykietowania na wyspecjalizowanym układzie.

Aby zobaczyć jakie wartości mogą przyjąć przedstawione złożoności, rozważmy graf rozmiaru $n$.
Każdy graf rozmiaru $n$ może zostać oetykietowany w $n$ krokach, ponieważ ma tylko $n$ wierzchołków. Każdy stan etykietowania nie może również zawierać więcej niż $n$ elementów. Zatem górne ograniczenie możemy przedstawić następująco
$$ \forall G_{n} \in \mathbb{G}_{n} : \Pi_{ cc }^{ \parallel }(G_{n}) \leq \Pi_{ st }(G_{n}) \leq n^{2} . $$

Zobaczmy jak wyglądają złożoności dla grafu pełnego $K_{n} = (V = [n], E= \{
(i,j): 1 \leq i < j \leq n \})$ oraz dla $Q_{n} = (V = [n], E = \{ (i, i+1) : 1 \leq n \} )$.
$$ n(n - 1) / 2 \leq \Pi_{ cc }^{ \parallel }(K_{n}) \leq \Pi_{ st }(K_{n}) \leq n^2$$
Graf $K_{n}$ maksymalizuje złożoności etykietowania, a  $\Pi_{ cc }^{ \parallel }$ jest rożne tylko o stałą od $\Pi_{ st }$. Co oznacza, że koszt obliczania funkcji opartej na takim grafie byłby zdominowany przez koszt dostępu do pamięci, a wyspecjalizowane układy nie dały by dużej przewagi nad tradycyjnym procesorem. Jest to bardzo pożądane dla MHF, jednak ze względu na bardzo wysoki stopień grafu $K_{n}$, nie jest on przydatny przy konstruowaniu takich funkcji.
Stopień wchodzący w grafie $Q_{n}$ jest równy 1, jednak złożoność etykietowania jest bardzo niska
$$ \Pi_{ cc }^{ \parallel }(Q_{n}) = \Pi_{ st }(Q_{n}) \leq n. $$ 
Oznacza to, że koszt obliczania funkcji opartej na takim grafie (taką funkcją jest PBKDF2) nie jest zależny w dużej mierze od kosztu dostępu do pamięci nawet dla dużego $n$. 



\section{Superkoncentrator}
Superkoncentrator jest grafem, w którym moc zbioru przodków dla wierzchołków szybko rośnie wraz z numerem pokolenia. Oznacza to, że zbiór kolejnych wierzchołków, będzie posiadał liczebny zbiór rodziców, co czyni superkoncentrator bardzo przydatnym do konstrukcji MHF.
\begin{definition}[N-Superkoncentrator] Skierowany graf acykliczny $G = (V, E)$ o ustalonym stopniu wchodzącym, $N$ wejściach i
	$N$ wyjściach nazywany jest N-Superkoncentratorem, gdy dla każdego $k \in [N]$
	oraz dla każdej pary podzbiorów $V_{1} \subset V$ $k$ wejść i $V_{2} \subset V$ $k$ wyjść istnieje
	$k$ wierzchołkowo-rozłącznych ścieżek łączących wierzchołki ze zbioru $V_{1}$ z wierzchołkami w $V_{2}$.
\end{definition}

\begin{definition}[(N, $\lambda$)-Superkoncentrator] Niech $G_{i}, i = 0, \dots, \lambda-1$ będą N-Superkoncentratorami.
	Niech graf $G$ będzie połączeniem wyjść $G_{i}$ do odpowiadających wejść w $G_{i+1}$ dla $i = 0, \dots, \lambda - 2$.
	Graf $G$ jest nazywany (N, $\lambda$)-Superkoncentratorem.
\end{definition}

\begin{lemma}[Ograniczenie dolne dla (N, $ \lambda $)-Superkoncentratora] \cite[Lemat 1]{rs}
	Etykietowanie (N, $\lambda$)-Superkoncentratora używając $S \leq N/20$ etykiet, wymaga $T$ kroków, gdzie
	$$ T \geq N \left( \frac{ \lambda N}{64 S} \right) ^{ \lambda }.$$
\end{lemma}

\section{Grafy depth-robust}

Alwen i Blocki w swojej pracy \cite{depth}
pokazali, że istnieje zależność między złożonością etykietowania, a własnością depth-robustness. Na podstawie tej właściwości potrafimy określić dolne i górne ograniczenie $\Pi_{ cc }^{ \parallel }$.

\begin{definition}[Depth-robustness] Dla $n \in \mathbb{N}$ oraz $e, d \in [n]$ DAG $G = (V, E)$
	jest (e, d)-depth-robust, jeżeli
	$$ \forall S \subset V \ | S | \leq e \Rightarrow \mathbf{depth}(G - S) \geq d.$$
\end{definition}

\begin{theorem} \cite[Twierdzenie 4]{depth}
	Niech DAG G będzie (e, d)-depth-robust, wtedy $ \Pi_{ cc }^{ \parallel } > ed$.
\end{theorem}

\begin{definition}
	Jeżeli graf $G$ nie jest (e,d)-depth-roubust to nazywany jest (e,d)-reducible.
\end{definition}

\begin{theorem} \cite[Twierdzenie 10]{depth} \label{1::redu}
	Niech $G \in \mathbb{G}_{n, \delta}$ taki, że $G$ jest (e,d)-reducible. Wtedy
	$$ \Pi_{cc}^{\parallel}(G) = O \left( \min_{g \in [d,n]} \Big \lbrace n \left( \frac{dn}{g} + \delta g + e \right) \Big \rbrace \right) $$
	biorąc $g = \sqrt{ \frac{dn}{g}}$ upraszcza się to do $ \Pi_{cc}^{\parallel}(G) = O \left( n ( \sqrt{dn \delta} + e) \right)$.
\end{theorem}

\section{Grafy rozproszone}

\begin{definition}
	[Zależność, ang. \textit{dependency}] Niech $G = (V, E)$ będzie acyklicznym grafem skierowanym.
	Niech $L \subseteq V$.
	Mówimy, że $L$ ma ($z$, $g$)-dependency jeżeli istnieją wierzchołkowo rozłączne ścieżki $p_{1}, \dots , p_{z}$ kończące się w $L$, gdzie każda jest długości co najmniej $g$.
\end{definition}

\begin{definition}
	[Graf rozproszony, ang. \textit{dispresed}] Niech $g, k \in \mathbb{N}$ i $g \geq k$. DAG G jest nazywany (g, k)-dispresed jeżeli istnieje uporządkowanie jego wierzchołków takie, że następujące warunki są spełnione.
	Niech $[k]$ oznacza ostatnie $k$ wierzchołków o uporządkowaniu G i niech $L_{j} = [jg, (j + 1)g - 1]$ będzie j-tym podprzedziałem.
	Wtedy $\forall j \in [ \lfloor k / g \rfloor ]$ przedział $L_{j}$ ma (g, g)-dependency.
	W ogólności, jeżeli dla $ \epsilon \in (0, 1] $ każdy przedział $L_{j}$ ma tylko ($\epsilon$g, g)-dependency, graf G nazywany jest ($\epsilon$, g, g)-dispresed.
\end{definition}

\begin{definition}
	Acykliczny graf skierowany $G = (V, E)$ nazywany jest ($\lambda$,$\epsilon$,g,k)-dispresed jeżeli istnieje $\lambda \in \mathbb{N}^{+} $ rozłącznych podzbiorów wierzchołków \{$ L_{i} \subseteq V$\},
	każdy o rozmiarze $k$ oraz spełnione są następujące warunki.
	\begin{enumerate}
		\item Dla każdego $L_{i}$ istnieje ścieżka przechodząca przez wszystkie wierzchołki $L_{i}$.
		
		\item Dla ustalonego porządku topologicznego G. Dla każdego $i \in [\lambda]$ niech
		$G_{i}$ będzie podgrafem G, zawierającym wszystkie wierzchołki z G, aż do ostatniego wierzchołka z $L_{i}$. $G_{i}$ jest ($\epsilon$,g,k)-dispresed.
	\end{enumerate}
	Zbiór grafów, które są ($\lambda$, $\epsilon$, g, k)-dispresed oznaczamy jako $\mathbb{D}_{\epsilon,g}^{\lambda,k}$.
\end{definition}

\begin{theorem} \cite[Twierdzenie 6]{depth} \label{1::disp}
	Niech $G \in \mathbb{D}_{\epsilon,g}^{\lambda,k}$.
	$$ \Pi_{cc}^{\parallel}(G) \geq \epsilon \lambda g \left( \frac{k}{2} - g \right) $$
\end{theorem}


\section{Grafy rzędowe}

\begin{definition}[Graf N rzędowy] Niech $n, N \in \mathbb{N}^{+}$ takie, że $N + 1$ dzieli $n$ oraz niech $k=n/(N + 1)$. Mówimy, że graf $G$ jest $N$ rzędowy, jeżeli $G$ zawiera ścieżkę przechodzącą przez $n$ wierzchołków $(v_{1},\dots,v_{n})$ oraz dzieląc go na rzędy $L_{j} = \{v_{jk + 1},\dots,v_{jk + k} \}$, dla $j \in \{0,\dots,N\}$, pozostałe krawędzie łączą wierzchołki z niższego rzędu $L_{j}$ jedynie z wierzchołkami z wyższych rzędów $L_{i}$, $i \in \{ j+1,\dots,N \}$.
\end{definition}



\begin{lemma} \cite[Lemat 4.2]{alwen2016efficiently} \label{1::rze}
	Niech $G$ będzie $N$ rzędowym grafem, wtedy dla dowolnego $t \in \mathbb{N}^{+}$, $G$ jest $(n/t, N t + t - N -1)$-reducible.
\end{lemma}






